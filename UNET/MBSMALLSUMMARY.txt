C:\ProgramData\Anaconda3\python.exe C:/Users/Admin/Downloads/pytorch_ipynb/UNETSUMMARY.py
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [4, 16, 320, 240]             432
       BatchNorm2d-2          [4, 16, 320, 240]              32
             ReLU6-3          [4, 16, 320, 240]               0
         h_sigmoid-4          [4, 16, 320, 240]               0
           h_swish-5          [4, 16, 320, 240]               0
            Conv2d-6          [4, 16, 160, 120]             144
       BatchNorm2d-7          [4, 16, 160, 120]              32
              ReLU-8          [4, 16, 160, 120]               0
 AdaptiveAvgPool2d-9              [4, 16, 1, 1]               0
           Linear-10                     [4, 8]             136
             ReLU-11                     [4, 8]               0
           Linear-12                    [4, 16]             144
            ReLU6-13                    [4, 16]               0
        h_sigmoid-14                    [4, 16]               0
          SELayer-15          [4, 16, 160, 120]               0
           Conv2d-16          [4, 16, 160, 120]             256
      BatchNorm2d-17          [4, 16, 160, 120]              32
 InvertedResidual-18          [4, 16, 160, 120]               0
           Conv2d-19          [4, 72, 160, 120]           1,152
      BatchNorm2d-20          [4, 72, 160, 120]             144
             ReLU-21          [4, 72, 160, 120]               0
           Conv2d-22            [4, 72, 80, 60]             648
      BatchNorm2d-23            [4, 72, 80, 60]             144
         Identity-24            [4, 72, 80, 60]               0
             ReLU-25            [4, 72, 80, 60]               0
           Conv2d-26            [4, 24, 80, 60]           1,728
      BatchNorm2d-27            [4, 24, 80, 60]              48
 InvertedResidual-28            [4, 24, 80, 60]               0
           Conv2d-29            [4, 88, 80, 60]           2,112
      BatchNorm2d-30            [4, 88, 80, 60]             176
             ReLU-31            [4, 88, 80, 60]               0
           Conv2d-32            [4, 88, 80, 60]             792
      BatchNorm2d-33            [4, 88, 80, 60]             176
         Identity-34            [4, 88, 80, 60]               0
             ReLU-35            [4, 88, 80, 60]               0
           Conv2d-36            [4, 24, 80, 60]           2,112
      BatchNorm2d-37            [4, 24, 80, 60]              48
 InvertedResidual-38            [4, 24, 80, 60]               0
           Conv2d-39            [4, 96, 80, 60]           2,304
      BatchNorm2d-40            [4, 96, 80, 60]             192
            ReLU6-41            [4, 96, 80, 60]               0
        h_sigmoid-42            [4, 96, 80, 60]               0
          h_swish-43            [4, 96, 80, 60]               0
           Conv2d-44            [4, 96, 40, 30]           2,400
      BatchNorm2d-45            [4, 96, 40, 30]             192
AdaptiveAvgPool2d-46              [4, 96, 1, 1]               0
           Linear-47                    [4, 24]           2,328
             ReLU-48                    [4, 24]               0
           Linear-49                    [4, 96]           2,400
            ReLU6-50                    [4, 96]               0
        h_sigmoid-51                    [4, 96]               0
          SELayer-52            [4, 96, 40, 30]               0
            ReLU6-53            [4, 96, 40, 30]               0
        h_sigmoid-54            [4, 96, 40, 30]               0
          h_swish-55            [4, 96, 40, 30]               0
           Conv2d-56            [4, 40, 40, 30]           3,840
      BatchNorm2d-57            [4, 40, 40, 30]              80
 InvertedResidual-58            [4, 40, 40, 30]               0
           Conv2d-59           [4, 240, 40, 30]           9,600
      BatchNorm2d-60           [4, 240, 40, 30]             480
            ReLU6-61           [4, 240, 40, 30]               0
        h_sigmoid-62           [4, 240, 40, 30]               0
          h_swish-63           [4, 240, 40, 30]               0
           Conv2d-64           [4, 240, 40, 30]           6,000
      BatchNorm2d-65           [4, 240, 40, 30]             480
AdaptiveAvgPool2d-66             [4, 240, 1, 1]               0
           Linear-67                    [4, 64]          15,424
             ReLU-68                    [4, 64]               0
           Linear-69                   [4, 240]          15,600
            ReLU6-70                   [4, 240]               0
        h_sigmoid-71                   [4, 240]               0
          SELayer-72           [4, 240, 40, 30]               0
            ReLU6-73           [4, 240, 40, 30]               0
        h_sigmoid-74           [4, 240, 40, 30]               0
          h_swish-75           [4, 240, 40, 30]               0
           Conv2d-76            [4, 40, 40, 30]           9,600
      BatchNorm2d-77            [4, 40, 40, 30]              80
 InvertedResidual-78            [4, 40, 40, 30]               0
           Conv2d-79           [4, 240, 40, 30]           9,600
      BatchNorm2d-80           [4, 240, 40, 30]             480
            ReLU6-81           [4, 240, 40, 30]               0
        h_sigmoid-82           [4, 240, 40, 30]               0
          h_swish-83           [4, 240, 40, 30]               0
           Conv2d-84           [4, 240, 40, 30]           6,000
      BatchNorm2d-85           [4, 240, 40, 30]             480
AdaptiveAvgPool2d-86             [4, 240, 1, 1]               0
           Linear-87                    [4, 64]          15,424
             ReLU-88                    [4, 64]               0
           Linear-89                   [4, 240]          15,600
            ReLU6-90                   [4, 240]               0
        h_sigmoid-91                   [4, 240]               0
          SELayer-92           [4, 240, 40, 30]               0
            ReLU6-93           [4, 240, 40, 30]               0
        h_sigmoid-94           [4, 240, 40, 30]               0
          h_swish-95           [4, 240, 40, 30]               0
           Conv2d-96            [4, 40, 40, 30]           9,600
      BatchNorm2d-97            [4, 40, 40, 30]              80
 InvertedResidual-98            [4, 40, 40, 30]               0
           Conv2d-99           [4, 120, 40, 30]           4,800
     BatchNorm2d-100           [4, 120, 40, 30]             240
           ReLU6-101           [4, 120, 40, 30]               0
       h_sigmoid-102           [4, 120, 40, 30]               0
         h_swish-103           [4, 120, 40, 30]               0
          Conv2d-104           [4, 120, 40, 30]           3,000
     BatchNorm2d-105           [4, 120, 40, 30]             240
AdaptiveAvgPool2d-106             [4, 120, 1, 1]               0
          Linear-107                    [4, 32]           3,872
            ReLU-108                    [4, 32]               0
          Linear-109                   [4, 120]           3,960
           ReLU6-110                   [4, 120]               0
       h_sigmoid-111                   [4, 120]               0
         SELayer-112           [4, 120, 40, 30]               0
           ReLU6-113           [4, 120, 40, 30]               0
       h_sigmoid-114           [4, 120, 40, 30]               0
         h_swish-115           [4, 120, 40, 30]               0
          Conv2d-116            [4, 48, 40, 30]           5,760
     BatchNorm2d-117            [4, 48, 40, 30]              96
InvertedResidual-118            [4, 48, 40, 30]               0
          Conv2d-119           [4, 144, 40, 30]           6,912
     BatchNorm2d-120           [4, 144, 40, 30]             288
           ReLU6-121           [4, 144, 40, 30]               0
       h_sigmoid-122           [4, 144, 40, 30]               0
         h_swish-123           [4, 144, 40, 30]               0
          Conv2d-124           [4, 144, 40, 30]           3,600
     BatchNorm2d-125           [4, 144, 40, 30]             288
AdaptiveAvgPool2d-126             [4, 144, 1, 1]               0
          Linear-127                    [4, 40]           5,800
            ReLU-128                    [4, 40]               0
          Linear-129                   [4, 144]           5,904
           ReLU6-130                   [4, 144]               0
       h_sigmoid-131                   [4, 144]               0
         SELayer-132           [4, 144, 40, 30]               0
           ReLU6-133           [4, 144, 40, 30]               0
       h_sigmoid-134           [4, 144, 40, 30]               0
         h_swish-135           [4, 144, 40, 30]               0
          Conv2d-136            [4, 48, 40, 30]           6,912
     BatchNorm2d-137            [4, 48, 40, 30]              96
InvertedResidual-138            [4, 48, 40, 30]               0
          Conv2d-139           [4, 288, 40, 30]          13,824
     BatchNorm2d-140           [4, 288, 40, 30]             576
           ReLU6-141           [4, 288, 40, 30]               0
       h_sigmoid-142           [4, 288, 40, 30]               0
         h_swish-143           [4, 288, 40, 30]               0
          Conv2d-144           [4, 288, 20, 15]           7,200
     BatchNorm2d-145           [4, 288, 20, 15]             576
AdaptiveAvgPool2d-146             [4, 288, 1, 1]               0
          Linear-147                    [4, 72]          20,808
            ReLU-148                    [4, 72]               0
          Linear-149                   [4, 288]          21,024
           ReLU6-150                   [4, 288]               0
       h_sigmoid-151                   [4, 288]               0
         SELayer-152           [4, 288, 20, 15]               0
           ReLU6-153           [4, 288, 20, 15]               0
       h_sigmoid-154           [4, 288, 20, 15]               0
         h_swish-155           [4, 288, 20, 15]               0
          Conv2d-156            [4, 96, 20, 15]          27,648
     BatchNorm2d-157            [4, 96, 20, 15]             192
InvertedResidual-158            [4, 96, 20, 15]               0
          Conv2d-159           [4, 576, 20, 15]          55,296
     BatchNorm2d-160           [4, 576, 20, 15]           1,152
           ReLU6-161           [4, 576, 20, 15]               0
       h_sigmoid-162           [4, 576, 20, 15]               0
         h_swish-163           [4, 576, 20, 15]               0
          Conv2d-164           [4, 576, 20, 15]          14,400
     BatchNorm2d-165           [4, 576, 20, 15]           1,152
AdaptiveAvgPool2d-166             [4, 576, 1, 1]               0
          Linear-167                   [4, 144]          83,088
            ReLU-168                   [4, 144]               0
          Linear-169                   [4, 576]          83,520
           ReLU6-170                   [4, 576]               0
       h_sigmoid-171                   [4, 576]               0
         SELayer-172           [4, 576, 20, 15]               0
           ReLU6-173           [4, 576, 20, 15]               0
       h_sigmoid-174           [4, 576, 20, 15]               0
         h_swish-175           [4, 576, 20, 15]               0
          Conv2d-176            [4, 96, 20, 15]          55,296
     BatchNorm2d-177            [4, 96, 20, 15]             192
InvertedResidual-178            [4, 96, 20, 15]               0
          Conv2d-179           [4, 576, 20, 15]          55,296
     BatchNorm2d-180           [4, 576, 20, 15]           1,152
           ReLU6-181           [4, 576, 20, 15]               0
       h_sigmoid-182           [4, 576, 20, 15]               0
         h_swish-183           [4, 576, 20, 15]               0
          Conv2d-184           [4, 576, 20, 15]          14,400
     BatchNorm2d-185           [4, 576, 20, 15]           1,152
AdaptiveAvgPool2d-186             [4, 576, 1, 1]               0
          Linear-187                   [4, 144]          83,088
            ReLU-188                   [4, 144]               0
          Linear-189                   [4, 576]          83,520
           ReLU6-190                   [4, 576]               0
       h_sigmoid-191                   [4, 576]               0
         SELayer-192           [4, 576, 20, 15]               0
           ReLU6-193           [4, 576, 20, 15]               0
       h_sigmoid-194           [4, 576, 20, 15]               0
         h_swish-195           [4, 576, 20, 15]               0
          Conv2d-196            [4, 96, 20, 15]          55,296
     BatchNorm2d-197            [4, 96, 20, 15]             192
InvertedResidual-198            [4, 96, 20, 15]               0
        Upsample-199            [4, 96, 40, 30]               0
          Conv2d-200            [4, 68, 40, 30]          83,300
     BatchNorm2d-201            [4, 68, 40, 30]             136
            ReLU-202            [4, 68, 40, 30]               0
          Conv2d-203            [4, 40, 40, 30]          24,520
     BatchNorm2d-204            [4, 40, 40, 30]              80
            ReLU-205            [4, 40, 40, 30]               0
      DoubleConv-206            [4, 40, 40, 30]               0
              Up-207            [4, 40, 40, 30]               0
        Upsample-208            [4, 40, 80, 60]               0
          Conv2d-209            [4, 32, 80, 60]          18,464
     BatchNorm2d-210            [4, 32, 80, 60]              64
            ReLU-211            [4, 32, 80, 60]               0
          Conv2d-212            [4, 16, 80, 60]           4,624
     BatchNorm2d-213            [4, 16, 80, 60]              32
            ReLU-214            [4, 16, 80, 60]               0
      DoubleConv-215            [4, 16, 80, 60]               0
              Up-216            [4, 16, 80, 60]               0
        Upsample-217          [4, 16, 160, 120]               0
          Conv2d-218          [4, 16, 160, 120]           4,624
     BatchNorm2d-219          [4, 16, 160, 120]              32
            ReLU-220          [4, 16, 160, 120]               0
          Conv2d-221          [4, 16, 160, 120]           2,320
     BatchNorm2d-222          [4, 16, 160, 120]              32
            ReLU-223          [4, 16, 160, 120]               0
      DoubleConv-224          [4, 16, 160, 120]               0
              Up-225          [4, 16, 160, 120]               0
        Upsample-226          [4, 16, 320, 240]               0
          Conv2d-227          [4, 16, 320, 240]           4,624
     BatchNorm2d-228          [4, 16, 320, 240]              32
            ReLU-229          [4, 16, 320, 240]               0
          Conv2d-230          [4, 16, 320, 240]           2,320
     BatchNorm2d-231          [4, 16, 320, 240]              32
            ReLU-232          [4, 16, 320, 240]               0
      DoubleConv-233          [4, 16, 320, 240]               0
              Up-234          [4, 16, 320, 240]               0
        Upsample-235          [4, 16, 640, 480]               0
   UpwithoutConv-236          [4, 16, 640, 480]               0
          Conv2d-237           [4, 1, 640, 480]              17
         OutConv-238           [4, 1, 640, 480]               0
================================================================
Total params: 1,015,813
Trainable params: 1,015,813
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 14.06
Forward/backward pass size (MB): 1931.42
Params size (MB): 3.88
Estimated Total Size (MB): 1949.36
----------------------------------------------------------------
Unet(
  (featureNet): MobileNetV3(
    (features): Sequential(
      (0): Sequential(
        (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): h_swish(
          (sigmoid): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (1): InvertedResidual(
        (conv): Sequential(
          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)
          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): SELayer(
            (avg_pool): AdaptiveAvgPool2d(output_size=1)
            (fc): Sequential(
              (0): Linear(in_features=16, out_features=8, bias=True)
              (1): ReLU(inplace=True)
              (2): Linear(in_features=8, out_features=16, bias=True)
              (3): h_sigmoid(
                (relu): ReLU6(inplace=True)
              )
            )
          )
          (4): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): InvertedResidual(
        (conv): Sequential(
          (0): Conv2d(16, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(72, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=72, bias=False)
          (4): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Identity()
          (6): ReLU(inplace=True)
          (7): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (8): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): InvertedResidual(
        (conv): Sequential(
          (0): Conv2d(24, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(88, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=88, bias=False)
          (4): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Identity()
          (6): ReLU(inplace=True)
          (7): Conv2d(88, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (8): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): InvertedResidual(
        (conv): Sequential(
          (0): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): h_swish(
            (sigmoid): h_sigmoid(
              (relu): ReLU6(inplace=True)
            )
          )
          (3): Conv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=96, bias=False)
          (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): SELayer(
            (avg_pool): AdaptiveAvgPool2d(output_size=1)
            (fc): Sequential(
              (0): Linear(in_features=96, out_features=24, bias=True)
              (1): ReLU(inplace=True)
              (2): Linear(in_features=24, out_features=96, bias=True)
              (3): h_sigmoid(
                (relu): ReLU6(inplace=True)
              )
            )
          )
          (6): h_swish(
            (sigmoid): h_sigmoid(
              (relu): ReLU6(inplace=True)
            )
          )
          (7): Conv2d(96, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (8): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): InvertedResidual(
        (conv): Sequential(
          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): h_swish(
            (sigmoid): h_sigmoid(
              (relu): ReLU6(inplace=True)
            )
          )
          (3): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)
          (4): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): SELayer(
            (avg_pool): AdaptiveAvgPool2d(output_size=1)
            (fc): Sequential(
              (0): Linear(in_features=240, out_features=64, bias=True)
              (1): ReLU(inplace=True)
              (2): Linear(in_features=64, out_features=240, bias=True)
              (3): h_sigmoid(
                (relu): ReLU6(inplace=True)
              )
            )
          )
          (6): h_swish(
            (sigmoid): h_sigmoid(
              (relu): ReLU6(inplace=True)
            )
          )
          (7): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (8): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (6): InvertedResidual(
        (conv): Sequential(
          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): h_swish(
            (sigmoid): h_sigmoid(
              (relu): ReLU6(inplace=True)
            )
          )
          (3): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)
          (4): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): SELayer(
            (avg_pool): AdaptiveAvgPool2d(output_size=1)
            (fc): Sequential(
              (0): Linear(in_features=240, out_features=64, bias=True)
              (1): ReLU(inplace=True)
              (2): Linear(in_features=64, out_features=240, bias=True)
              (3): h_sigmoid(
                (relu): ReLU6(inplace=True)
              )
            )
          )
          (6): h_swish(
            (sigmoid): h_sigmoid(
              (relu): ReLU6(inplace=True)
            )
          )
          (7): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (8): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (7): InvertedResidual(
        (conv): Sequential(
          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): h_swish(
            (sigmoid): h_sigmoid(
              (relu): ReLU6(inplace=True)
            )
          )
          (3): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)
          (4): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): SELayer(
            (avg_pool): AdaptiveAvgPool2d(output_size=1)
            (fc): Sequential(
              (0): Linear(in_features=120, out_features=32, bias=True)
              (1): ReLU(inplace=True)
              (2): Linear(in_features=32, out_features=120, bias=True)
              (3): h_sigmoid(
                (relu): ReLU6(inplace=True)
              )
            )
          )
          (6): h_swish(
            (sigmoid): h_sigmoid(
              (relu): ReLU6(inplace=True)
            )
          )
          (7): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (8): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (8): InvertedResidual(
        (conv): Sequential(
          (0): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): h_swish(
            (sigmoid): h_sigmoid(
              (relu): ReLU6(inplace=True)
            )
          )
          (3): Conv2d(144, 144, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=144, bias=False)
          (4): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): SELayer(
            (avg_pool): AdaptiveAvgPool2d(output_size=1)
            (fc): Sequential(
              (0): Linear(in_features=144, out_features=40, bias=True)
              (1): ReLU(inplace=True)
              (2): Linear(in_features=40, out_features=144, bias=True)
              (3): h_sigmoid(
                (relu): ReLU6(inplace=True)
              )
            )
          )
          (6): h_swish(
            (sigmoid): h_sigmoid(
              (relu): ReLU6(inplace=True)
            )
          )
          (7): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (8): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (9): InvertedResidual(
        (conv): Sequential(
          (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): h_swish(
            (sigmoid): h_sigmoid(
              (relu): ReLU6(inplace=True)
            )
          )
          (3): Conv2d(288, 288, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=288, bias=False)
          (4): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): SELayer(
            (avg_pool): AdaptiveAvgPool2d(output_size=1)
            (fc): Sequential(
              (0): Linear(in_features=288, out_features=72, bias=True)
              (1): ReLU(inplace=True)
              (2): Linear(in_features=72, out_features=288, bias=True)
              (3): h_sigmoid(
                (relu): ReLU6(inplace=True)
              )
            )
          )
          (6): h_swish(
            (sigmoid): h_sigmoid(
              (relu): ReLU6(inplace=True)
            )
          )
          (7): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (8): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (10): InvertedResidual(
        (conv): Sequential(
          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): h_swish(
            (sigmoid): h_sigmoid(
              (relu): ReLU6(inplace=True)
            )
          )
          (3): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)
          (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): SELayer(
            (avg_pool): AdaptiveAvgPool2d(output_size=1)
            (fc): Sequential(
              (0): Linear(in_features=576, out_features=144, bias=True)
              (1): ReLU(inplace=True)
              (2): Linear(in_features=144, out_features=576, bias=True)
              (3): h_sigmoid(
                (relu): ReLU6(inplace=True)
              )
            )
          )
          (6): h_swish(
            (sigmoid): h_sigmoid(
              (relu): ReLU6(inplace=True)
            )
          )
          (7): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (8): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (11): InvertedResidual(
        (conv): Sequential(
          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): h_swish(
            (sigmoid): h_sigmoid(
              (relu): ReLU6(inplace=True)
            )
          )
          (3): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)
          (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): SELayer(
            (avg_pool): AdaptiveAvgPool2d(output_size=1)
            (fc): Sequential(
              (0): Linear(in_features=576, out_features=144, bias=True)
              (1): ReLU(inplace=True)
              (2): Linear(in_features=144, out_features=576, bias=True)
              (3): h_sigmoid(
                (relu): ReLU6(inplace=True)
              )
            )
          )
          (6): h_swish(
            (sigmoid): h_sigmoid(
              (relu): ReLU6(inplace=True)
            )
          )
          (7): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (8): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (conv): Sequential(
      (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): h_swish(
        (sigmoid): h_sigmoid(
          (relu): ReLU6(inplace=True)
        )
      )
    )
    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
    (classifier): Sequential(
      (0): Linear(in_features=576, out_features=1024, bias=True)
      (1): h_swish(
        (sigmoid): h_sigmoid(
          (relu): ReLU6(inplace=True)
        )
      )
      (2): Dropout(p=0.2, inplace=False)
    )
    (linear): Linear(in_features=1024, out_features=2, bias=True)
  )
  (up1): Up(
    (up): Upsample(scale_factor=2.0, mode=bilinear)
    (conv): DoubleConv(
      (double_conv): Sequential(
        (0): Conv2d(136, 68, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): BatchNorm2d(68, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(68, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (4): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU(inplace=True)
      )
    )
  )
  (up2): Up(
    (up): Upsample(scale_factor=2.0, mode=bilinear)
    (conv): DoubleConv(
      (double_conv): Sequential(
        (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU(inplace=True)
      )
    )
  )
  (up3): Up(
    (up): Upsample(scale_factor=2.0, mode=bilinear)
    (conv): DoubleConv(
      (double_conv): Sequential(
        (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU(inplace=True)
      )
    )
  )
  (up4): Up(
    (up): Upsample(scale_factor=2.0, mode=bilinear)
    (conv): DoubleConv(
      (double_conv): Sequential(
        (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU(inplace=True)
      )
    )
  )
  (up5): UpwithoutConv(
    (up): Upsample(scale_factor=2.0, mode=bilinear)
    (conv): DoubleConv(
      (double_conv): Sequential(
        (0): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU(inplace=True)
      )
    )
  )
  (outc): OutConv(
    (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1))
  )
)

Process finished with exit code 0
