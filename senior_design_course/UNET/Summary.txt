C:\ProgramData\Anaconda3\python.exe C:/Users/Admin/Downloads/pytorch_ipynb/UNETSUMMARY.py
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [2, 16, 320, 240]             432
       BatchNorm2d-2          [2, 16, 320, 240]              32
             ReLU6-3          [2, 16, 320, 240]               0
         h_sigmoid-4          [2, 16, 320, 240]               0
           h_swish-5          [2, 16, 320, 240]               0
            Conv2d-6          [2, 16, 320, 240]             144
       BatchNorm2d-7          [2, 16, 320, 240]              32
              ReLU-8          [2, 16, 320, 240]               0
          Identity-9          [2, 16, 320, 240]               0
           Conv2d-10          [2, 16, 320, 240]             256
      BatchNorm2d-11          [2, 16, 320, 240]              32
 InvertedResidual-12          [2, 16, 320, 240]               0
           Conv2d-13          [2, 64, 320, 240]           1,024
      BatchNorm2d-14          [2, 64, 320, 240]             128
             ReLU-15          [2, 64, 320, 240]               0
           Conv2d-16          [2, 64, 160, 120]             576
      BatchNorm2d-17          [2, 64, 160, 120]             128
         Identity-18          [2, 64, 160, 120]               0
             ReLU-19          [2, 64, 160, 120]               0
           Conv2d-20          [2, 24, 160, 120]           1,536
      BatchNorm2d-21          [2, 24, 160, 120]              48
 InvertedResidual-22          [2, 24, 160, 120]               0
           Conv2d-23          [2, 72, 160, 120]           1,728
      BatchNorm2d-24          [2, 72, 160, 120]             144
             ReLU-25          [2, 72, 160, 120]               0
           Conv2d-26          [2, 72, 160, 120]             648
      BatchNorm2d-27          [2, 72, 160, 120]             144
         Identity-28          [2, 72, 160, 120]               0
             ReLU-29          [2, 72, 160, 120]               0
           Conv2d-30          [2, 24, 160, 120]           1,728
      BatchNorm2d-31          [2, 24, 160, 120]              48
 InvertedResidual-32          [2, 24, 160, 120]               0
           Conv2d-33          [2, 72, 160, 120]           1,728
      BatchNorm2d-34          [2, 72, 160, 120]             144
             ReLU-35          [2, 72, 160, 120]               0
           Conv2d-36            [2, 72, 80, 60]           1,800
      BatchNorm2d-37            [2, 72, 80, 60]             144
AdaptiveAvgPool2d-38              [2, 72, 1, 1]               0
           Linear-39                    [2, 24]           1,752
             ReLU-40                    [2, 24]               0
           Linear-41                    [2, 72]           1,800
            ReLU6-42                    [2, 72]               0
        h_sigmoid-43                    [2, 72]               0
          SELayer-44            [2, 72, 80, 60]               0
             ReLU-45            [2, 72, 80, 60]               0
           Conv2d-46            [2, 40, 80, 60]           2,880
      BatchNorm2d-47            [2, 40, 80, 60]              80
 InvertedResidual-48            [2, 40, 80, 60]               0
           Conv2d-49           [2, 120, 80, 60]           4,800
      BatchNorm2d-50           [2, 120, 80, 60]             240
             ReLU-51           [2, 120, 80, 60]               0
           Conv2d-52           [2, 120, 80, 60]           3,000
      BatchNorm2d-53           [2, 120, 80, 60]             240
AdaptiveAvgPool2d-54             [2, 120, 1, 1]               0
           Linear-55                    [2, 32]           3,872
             ReLU-56                    [2, 32]               0
           Linear-57                   [2, 120]           3,960
            ReLU6-58                   [2, 120]               0
        h_sigmoid-59                   [2, 120]               0
          SELayer-60           [2, 120, 80, 60]               0
             ReLU-61           [2, 120, 80, 60]               0
           Conv2d-62            [2, 40, 80, 60]           4,800
      BatchNorm2d-63            [2, 40, 80, 60]              80
 InvertedResidual-64            [2, 40, 80, 60]               0
           Conv2d-65           [2, 120, 80, 60]           4,800
      BatchNorm2d-66           [2, 120, 80, 60]             240
             ReLU-67           [2, 120, 80, 60]               0
           Conv2d-68           [2, 120, 80, 60]           3,000
      BatchNorm2d-69           [2, 120, 80, 60]             240
AdaptiveAvgPool2d-70             [2, 120, 1, 1]               0
           Linear-71                    [2, 32]           3,872
             ReLU-72                    [2, 32]               0
           Linear-73                   [2, 120]           3,960
            ReLU6-74                   [2, 120]               0
        h_sigmoid-75                   [2, 120]               0
          SELayer-76           [2, 120, 80, 60]               0
             ReLU-77           [2, 120, 80, 60]               0
           Conv2d-78            [2, 40, 80, 60]           4,800
      BatchNorm2d-79            [2, 40, 80, 60]              80
 InvertedResidual-80            [2, 40, 80, 60]               0
           Conv2d-81           [2, 240, 80, 60]           9,600
      BatchNorm2d-82           [2, 240, 80, 60]             480
            ReLU6-83           [2, 240, 80, 60]               0
        h_sigmoid-84           [2, 240, 80, 60]               0
          h_swish-85           [2, 240, 80, 60]               0
           Conv2d-86           [2, 240, 40, 30]           2,160
      BatchNorm2d-87           [2, 240, 40, 30]             480
         Identity-88           [2, 240, 40, 30]               0
            ReLU6-89           [2, 240, 40, 30]               0
        h_sigmoid-90           [2, 240, 40, 30]               0
          h_swish-91           [2, 240, 40, 30]               0
           Conv2d-92            [2, 80, 40, 30]          19,200
      BatchNorm2d-93            [2, 80, 40, 30]             160
 InvertedResidual-94            [2, 80, 40, 30]               0
           Conv2d-95           [2, 200, 40, 30]          16,000
      BatchNorm2d-96           [2, 200, 40, 30]             400
            ReLU6-97           [2, 200, 40, 30]               0
        h_sigmoid-98           [2, 200, 40, 30]               0
          h_swish-99           [2, 200, 40, 30]               0
          Conv2d-100           [2, 200, 40, 30]           1,800
     BatchNorm2d-101           [2, 200, 40, 30]             400
        Identity-102           [2, 200, 40, 30]               0
           ReLU6-103           [2, 200, 40, 30]               0
       h_sigmoid-104           [2, 200, 40, 30]               0
         h_swish-105           [2, 200, 40, 30]               0
          Conv2d-106            [2, 80, 40, 30]          16,000
     BatchNorm2d-107            [2, 80, 40, 30]             160
InvertedResidual-108            [2, 80, 40, 30]               0
          Conv2d-109           [2, 184, 40, 30]          14,720
     BatchNorm2d-110           [2, 184, 40, 30]             368
           ReLU6-111           [2, 184, 40, 30]               0
       h_sigmoid-112           [2, 184, 40, 30]               0
         h_swish-113           [2, 184, 40, 30]               0
          Conv2d-114           [2, 184, 40, 30]           1,656
     BatchNorm2d-115           [2, 184, 40, 30]             368
        Identity-116           [2, 184, 40, 30]               0
           ReLU6-117           [2, 184, 40, 30]               0
       h_sigmoid-118           [2, 184, 40, 30]               0
         h_swish-119           [2, 184, 40, 30]               0
          Conv2d-120            [2, 80, 40, 30]          14,720
     BatchNorm2d-121            [2, 80, 40, 30]             160
InvertedResidual-122            [2, 80, 40, 30]               0
          Conv2d-123           [2, 184, 40, 30]          14,720
     BatchNorm2d-124           [2, 184, 40, 30]             368
           ReLU6-125           [2, 184, 40, 30]               0
       h_sigmoid-126           [2, 184, 40, 30]               0
         h_swish-127           [2, 184, 40, 30]               0
          Conv2d-128           [2, 184, 40, 30]           1,656
     BatchNorm2d-129           [2, 184, 40, 30]             368
        Identity-130           [2, 184, 40, 30]               0
           ReLU6-131           [2, 184, 40, 30]               0
       h_sigmoid-132           [2, 184, 40, 30]               0
         h_swish-133           [2, 184, 40, 30]               0
          Conv2d-134            [2, 80, 40, 30]          14,720
     BatchNorm2d-135            [2, 80, 40, 30]             160
InvertedResidual-136            [2, 80, 40, 30]               0
          Conv2d-137           [2, 480, 40, 30]          38,400
     BatchNorm2d-138           [2, 480, 40, 30]             960
           ReLU6-139           [2, 480, 40, 30]               0
       h_sigmoid-140           [2, 480, 40, 30]               0
         h_swish-141           [2, 480, 40, 30]               0
          Conv2d-142           [2, 480, 40, 30]           4,320
     BatchNorm2d-143           [2, 480, 40, 30]             960
AdaptiveAvgPool2d-144             [2, 480, 1, 1]               0
          Linear-145                   [2, 120]          57,720
            ReLU-146                   [2, 120]               0
          Linear-147                   [2, 480]          58,080
           ReLU6-148                   [2, 480]               0
       h_sigmoid-149                   [2, 480]               0
         SELayer-150           [2, 480, 40, 30]               0
           ReLU6-151           [2, 480, 40, 30]               0
       h_sigmoid-152           [2, 480, 40, 30]               0
         h_swish-153           [2, 480, 40, 30]               0
          Conv2d-154           [2, 112, 40, 30]          53,760
     BatchNorm2d-155           [2, 112, 40, 30]             224
InvertedResidual-156           [2, 112, 40, 30]               0
          Conv2d-157           [2, 672, 40, 30]          75,264
     BatchNorm2d-158           [2, 672, 40, 30]           1,344
           ReLU6-159           [2, 672, 40, 30]               0
       h_sigmoid-160           [2, 672, 40, 30]               0
         h_swish-161           [2, 672, 40, 30]               0
          Conv2d-162           [2, 672, 40, 30]           6,048
     BatchNorm2d-163           [2, 672, 40, 30]           1,344
AdaptiveAvgPool2d-164             [2, 672, 1, 1]               0
          Linear-165                   [2, 168]         113,064
            ReLU-166                   [2, 168]               0
          Linear-167                   [2, 672]         113,568
           ReLU6-168                   [2, 672]               0
       h_sigmoid-169                   [2, 672]               0
         SELayer-170           [2, 672, 40, 30]               0
           ReLU6-171           [2, 672, 40, 30]               0
       h_sigmoid-172           [2, 672, 40, 30]               0
         h_swish-173           [2, 672, 40, 30]               0
          Conv2d-174           [2, 112, 40, 30]          75,264
     BatchNorm2d-175           [2, 112, 40, 30]             224
InvertedResidual-176           [2, 112, 40, 30]               0
          Conv2d-177           [2, 672, 40, 30]          75,264
     BatchNorm2d-178           [2, 672, 40, 30]           1,344
           ReLU6-179           [2, 672, 40, 30]               0
       h_sigmoid-180           [2, 672, 40, 30]               0
         h_swish-181           [2, 672, 40, 30]               0
          Conv2d-182           [2, 672, 20, 15]          16,800
     BatchNorm2d-183           [2, 672, 20, 15]           1,344
AdaptiveAvgPool2d-184             [2, 672, 1, 1]               0
          Linear-185                   [2, 168]         113,064
            ReLU-186                   [2, 168]               0
          Linear-187                   [2, 672]         113,568
           ReLU6-188                   [2, 672]               0
       h_sigmoid-189                   [2, 672]               0
         SELayer-190           [2, 672, 20, 15]               0
           ReLU6-191           [2, 672, 20, 15]               0
       h_sigmoid-192           [2, 672, 20, 15]               0
         h_swish-193           [2, 672, 20, 15]               0
          Conv2d-194           [2, 160, 20, 15]         107,520
     BatchNorm2d-195           [2, 160, 20, 15]             320
InvertedResidual-196           [2, 160, 20, 15]               0
          Conv2d-197           [2, 960, 20, 15]         153,600
     BatchNorm2d-198           [2, 960, 20, 15]           1,920
           ReLU6-199           [2, 960, 20, 15]               0
       h_sigmoid-200           [2, 960, 20, 15]               0
         h_swish-201           [2, 960, 20, 15]               0
          Conv2d-202           [2, 960, 20, 15]          24,000
     BatchNorm2d-203           [2, 960, 20, 15]           1,920
AdaptiveAvgPool2d-204             [2, 960, 1, 1]               0
          Linear-205                   [2, 240]         230,640
            ReLU-206                   [2, 240]               0
          Linear-207                   [2, 960]         231,360
           ReLU6-208                   [2, 960]               0
       h_sigmoid-209                   [2, 960]               0
         SELayer-210           [2, 960, 20, 15]               0
           ReLU6-211           [2, 960, 20, 15]               0
       h_sigmoid-212           [2, 960, 20, 15]               0
         h_swish-213           [2, 960, 20, 15]               0
          Conv2d-214           [2, 160, 20, 15]         153,600
     BatchNorm2d-215           [2, 160, 20, 15]             320
InvertedResidual-216           [2, 160, 20, 15]               0
          Conv2d-217           [2, 960, 20, 15]         153,600
     BatchNorm2d-218           [2, 960, 20, 15]           1,920
           ReLU6-219           [2, 960, 20, 15]               0
       h_sigmoid-220           [2, 960, 20, 15]               0
         h_swish-221           [2, 960, 20, 15]               0
          Conv2d-222           [2, 960, 20, 15]          24,000
     BatchNorm2d-223           [2, 960, 20, 15]           1,920
AdaptiveAvgPool2d-224             [2, 960, 1, 1]               0
          Linear-225                   [2, 240]         230,640
            ReLU-226                   [2, 240]               0
          Linear-227                   [2, 960]         231,360
           ReLU6-228                   [2, 960]               0
       h_sigmoid-229                   [2, 960]               0
         SELayer-230           [2, 960, 20, 15]               0
           ReLU6-231           [2, 960, 20, 15]               0
       h_sigmoid-232           [2, 960, 20, 15]               0
         h_swish-233           [2, 960, 20, 15]               0
          Conv2d-234           [2, 160, 20, 15]         153,600
     BatchNorm2d-235           [2, 160, 20, 15]             320
InvertedResidual-236           [2, 160, 20, 15]               0
        Upsample-237           [2, 160, 40, 30]               0
          Conv2d-238           [2, 136, 40, 30]         333,064
     BatchNorm2d-239           [2, 136, 40, 30]             272
            ReLU-240           [2, 136, 40, 30]               0
          Conv2d-241            [2, 40, 40, 30]          49,000
     BatchNorm2d-242            [2, 40, 40, 30]              80
            ReLU-243            [2, 40, 40, 30]               0
      DoubleConv-244            [2, 40, 40, 30]               0
              Up-245            [2, 40, 40, 30]               0
        Upsample-246            [2, 40, 80, 60]               0
          Conv2d-247            [2, 40, 80, 60]          28,840
     BatchNorm2d-248            [2, 40, 80, 60]              80
            ReLU-249            [2, 40, 80, 60]               0
          Conv2d-250            [2, 24, 80, 60]           8,664
     BatchNorm2d-251            [2, 24, 80, 60]              48
            ReLU-252            [2, 24, 80, 60]               0
      DoubleConv-253            [2, 24, 80, 60]               0
              Up-254            [2, 24, 80, 60]               0
        Upsample-255          [2, 24, 160, 120]               0
          Conv2d-256          [2, 24, 160, 120]          10,392
     BatchNorm2d-257          [2, 24, 160, 120]              48
            ReLU-258          [2, 24, 160, 120]               0
          Conv2d-259          [2, 16, 160, 120]           3,472
     BatchNorm2d-260          [2, 16, 160, 120]              32
            ReLU-261          [2, 16, 160, 120]               0
      DoubleConv-262          [2, 16, 160, 120]               0
              Up-263          [2, 16, 160, 120]               0
        Upsample-264          [2, 16, 320, 240]               0
          Conv2d-265          [2, 16, 320, 240]           4,624
     BatchNorm2d-266          [2, 16, 320, 240]              32
            ReLU-267          [2, 16, 320, 240]               0
          Conv2d-268          [2, 16, 320, 240]           2,320
     BatchNorm2d-269          [2, 16, 320, 240]              32
            ReLU-270          [2, 16, 320, 240]               0
      DoubleConv-271          [2, 16, 320, 240]               0
              Up-272          [2, 16, 320, 240]               0
        Upsample-273          [2, 16, 640, 480]               0
   UpwithoutConv-274          [2, 16, 640, 480]               0
          Conv2d-275           [2, 1, 640, 480]              17
         OutConv-276           [2, 1, 640, 480]               0
================================================================
Total params: 3,257,449
Trainable params: 3,257,449
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 7.03
Forward/backward pass size (MB): 2037.00
Params size (MB): 12.43
Estimated Total Size (MB): 2056.45
----------------------------------------------------------------
Unet(
  (featureNet): MobileNetV3(
    (features): Sequential(
      (0): Sequential(
        (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): h_swish(
          (sigmoid): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
        )
      )
      (1): InvertedResidual(
        (conv): Sequential(
          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)
          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Identity()
          (4): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): InvertedResidual(
        (conv): Sequential(
          (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Identity()
          (6): ReLU(inplace=True)
          (7): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (8): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): InvertedResidual(
        (conv): Sequential(
          (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)
          (4): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Identity()
          (6): ReLU(inplace=True)
          (7): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (8): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): InvertedResidual(
        (conv): Sequential(
          (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)
          (4): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): SELayer(
            (avg_pool): AdaptiveAvgPool2d(output_size=1)
            (fc): Sequential(
              (0): Linear(in_features=72, out_features=24, bias=True)
              (1): ReLU(inplace=True)
              (2): Linear(in_features=24, out_features=72, bias=True)
              (3): h_sigmoid(
                (relu): ReLU6(inplace=True)
              )
            )
          )
          (6): ReLU(inplace=True)
          (7): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (8): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): InvertedResidual(
        (conv): Sequential(
          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)
          (4): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): SELayer(
            (avg_pool): AdaptiveAvgPool2d(output_size=1)
            (fc): Sequential(
              (0): Linear(in_features=120, out_features=32, bias=True)
              (1): ReLU(inplace=True)
              (2): Linear(in_features=32, out_features=120, bias=True)
              (3): h_sigmoid(
                (relu): ReLU6(inplace=True)
              )
            )
          )
          (6): ReLU(inplace=True)
          (7): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (8): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (6): InvertedResidual(
        (conv): Sequential(
          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)
          (4): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): SELayer(
            (avg_pool): AdaptiveAvgPool2d(output_size=1)
            (fc): Sequential(
              (0): Linear(in_features=120, out_features=32, bias=True)
              (1): ReLU(inplace=True)
              (2): Linear(in_features=32, out_features=120, bias=True)
              (3): h_sigmoid(
                (relu): ReLU6(inplace=True)
              )
            )
          )
          (6): ReLU(inplace=True)
          (7): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (8): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (7): InvertedResidual(
        (conv): Sequential(
          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): h_swish(
            (sigmoid): h_sigmoid(
              (relu): ReLU6(inplace=True)
            )
          )
          (3): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)
          (4): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Identity()
          (6): h_swish(
            (sigmoid): h_sigmoid(
              (relu): ReLU6(inplace=True)
            )
          )
          (7): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (8): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (8): InvertedResidual(
        (conv): Sequential(
          (0): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): h_swish(
            (sigmoid): h_sigmoid(
              (relu): ReLU6(inplace=True)
            )
          )
          (3): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)
          (4): BatchNorm2d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Identity()
          (6): h_swish(
            (sigmoid): h_sigmoid(
              (relu): ReLU6(inplace=True)
            )
          )
          (7): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (8): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (9): InvertedResidual(
        (conv): Sequential(
          (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): h_swish(
            (sigmoid): h_sigmoid(
              (relu): ReLU6(inplace=True)
            )
          )
          (3): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)
          (4): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Identity()
          (6): h_swish(
            (sigmoid): h_sigmoid(
              (relu): ReLU6(inplace=True)
            )
          )
          (7): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (8): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (10): InvertedResidual(
        (conv): Sequential(
          (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): h_swish(
            (sigmoid): h_sigmoid(
              (relu): ReLU6(inplace=True)
            )
          )
          (3): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)
          (4): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Identity()
          (6): h_swish(
            (sigmoid): h_sigmoid(
              (relu): ReLU6(inplace=True)
            )
          )
          (7): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (8): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (11): InvertedResidual(
        (conv): Sequential(
          (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): h_swish(
            (sigmoid): h_sigmoid(
              (relu): ReLU6(inplace=True)
            )
          )
          (3): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)
          (4): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): SELayer(
            (avg_pool): AdaptiveAvgPool2d(output_size=1)
            (fc): Sequential(
              (0): Linear(in_features=480, out_features=120, bias=True)
              (1): ReLU(inplace=True)
              (2): Linear(in_features=120, out_features=480, bias=True)
              (3): h_sigmoid(
                (relu): ReLU6(inplace=True)
              )
            )
          )
          (6): h_swish(
            (sigmoid): h_sigmoid(
              (relu): ReLU6(inplace=True)
            )
          )
          (7): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (8): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (12): InvertedResidual(
        (conv): Sequential(
          (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): h_swish(
            (sigmoid): h_sigmoid(
              (relu): ReLU6(inplace=True)
            )
          )
          (3): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)
          (4): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): SELayer(
            (avg_pool): AdaptiveAvgPool2d(output_size=1)
            (fc): Sequential(
              (0): Linear(in_features=672, out_features=168, bias=True)
              (1): ReLU(inplace=True)
              (2): Linear(in_features=168, out_features=672, bias=True)
              (3): h_sigmoid(
                (relu): ReLU6(inplace=True)
              )
            )
          )
          (6): h_swish(
            (sigmoid): h_sigmoid(
              (relu): ReLU6(inplace=True)
            )
          )
          (7): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (8): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (13): InvertedResidual(
        (conv): Sequential(
          (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): h_swish(
            (sigmoid): h_sigmoid(
              (relu): ReLU6(inplace=True)
            )
          )
          (3): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)
          (4): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): SELayer(
            (avg_pool): AdaptiveAvgPool2d(output_size=1)
            (fc): Sequential(
              (0): Linear(in_features=672, out_features=168, bias=True)
              (1): ReLU(inplace=True)
              (2): Linear(in_features=168, out_features=672, bias=True)
              (3): h_sigmoid(
                (relu): ReLU6(inplace=True)
              )
            )
          )
          (6): h_swish(
            (sigmoid): h_sigmoid(
              (relu): ReLU6(inplace=True)
            )
          )
          (7): Conv2d(672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (8): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (14): InvertedResidual(
        (conv): Sequential(
          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): h_swish(
            (sigmoid): h_sigmoid(
              (relu): ReLU6(inplace=True)
            )
          )
          (3): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)
          (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): SELayer(
            (avg_pool): AdaptiveAvgPool2d(output_size=1)
            (fc): Sequential(
              (0): Linear(in_features=960, out_features=240, bias=True)
              (1): ReLU(inplace=True)
              (2): Linear(in_features=240, out_features=960, bias=True)
              (3): h_sigmoid(
                (relu): ReLU6(inplace=True)
              )
            )
          )
          (6): h_swish(
            (sigmoid): h_sigmoid(
              (relu): ReLU6(inplace=True)
            )
          )
          (7): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (8): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (15): InvertedResidual(
        (conv): Sequential(
          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): h_swish(
            (sigmoid): h_sigmoid(
              (relu): ReLU6(inplace=True)
            )
          )
          (3): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)
          (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): SELayer(
            (avg_pool): AdaptiveAvgPool2d(output_size=1)
            (fc): Sequential(
              (0): Linear(in_features=960, out_features=240, bias=True)
              (1): ReLU(inplace=True)
              (2): Linear(in_features=240, out_features=960, bias=True)
              (3): h_sigmoid(
                (relu): ReLU6(inplace=True)
              )
            )
          )
          (6): h_swish(
            (sigmoid): h_sigmoid(
              (relu): ReLU6(inplace=True)
            )
          )
          (7): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (8): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (conv): Sequential(
      (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): h_swish(
        (sigmoid): h_sigmoid(
          (relu): ReLU6(inplace=True)
        )
      )
    )
    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
    (classifier): Sequential(
      (0): Linear(in_features=960, out_features=1280, bias=True)
      (1): h_swish(
        (sigmoid): h_sigmoid(
          (relu): ReLU6(inplace=True)
        )
      )
      (2): Dropout(p=0.2, inplace=False)
    )
    (linear): Linear(in_features=1280, out_features=2, bias=True)
  )
  (up1): Up(
    (up): Upsample(scale_factor=2.0, mode=bilinear)
    (conv): DoubleConv(
      (double_conv): Sequential(
        (0): Conv2d(272, 136, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(136, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (4): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU(inplace=True)
      )
    )
  )
  (up2): Up(
    (up): Upsample(scale_factor=2.0, mode=bilinear)
    (conv): DoubleConv(
      (double_conv): Sequential(
        (0): Conv2d(80, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(40, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU(inplace=True)
      )
    )
  )
  (up3): Up(
    (up): Upsample(scale_factor=2.0, mode=bilinear)
    (conv): DoubleConv(
      (double_conv): Sequential(
        (0): Conv2d(48, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(24, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU(inplace=True)
      )
    )
  )
  (up4): Up(
    (up): Upsample(scale_factor=2.0, mode=bilinear)
    (conv): DoubleConv(
      (double_conv): Sequential(
        (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU(inplace=True)
      )
    )
  )
  (up5): UpwithoutConv(
    (up): Upsample(scale_factor=2.0, mode=bilinear)
    (conv): DoubleConv(
      (double_conv): Sequential(
        (0): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU(inplace=True)
      )
    )
  )
  (outc): OutConv(
    (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1))
  )
)

Process finished with exit code 0
